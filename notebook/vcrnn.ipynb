{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import skimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, BatchNormalization, Reshape\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import GRU\n",
    "from keras.callbacks import *\n",
    "from keras.layers.merge import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = '0123456789+-*/=()'\n",
    "width, height, n_len, n_class = 400, 80, 4, len(characters) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    ds = '0123456789'\n",
    "    ts = ['{}{}{}{}{}', '({}{}{}){}{}', '{}{}({}{}{})']\n",
    "    os = '+-*/'\n",
    "    # os = ['+', '-', 'times', 'div']\n",
    "    cs = [random.choice(ds) if x % 2 == 0 else random.choice(os) for x in range(5)]\n",
    "    return random.choice(ts).format(*cs)\n",
    "\n",
    "\n",
    "def get_img_by_char(char, base_path='./pre_ocr'):\n",
    "    \"\"\"\n",
    "    get a img by giving char\n",
    "    :param char:\n",
    "    :param base_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    opdict = {'+': 10, '-': 11, '*': 12, '/': 13, '=': 14, '(': 15, ')': 16}\n",
    "    if char in opdict.keys():\n",
    "        char = opdict[char]\n",
    "    path = os.path.join(base_path, str(char))\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    rdm = random.randint(0, len(files) - 1)\n",
    "    \n",
    "    if rdm >= len(files):\n",
    "        print(path, len(files), rdm)\n",
    "        \n",
    "    file = files[rdm]\n",
    "    path = os.path.join(path, file)\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "def get_sequence_img(chars):\n",
    "    x = get_img_by_char(chars[0])\n",
    "    for i in range(1, len(chars)):\n",
    "        x = np.hstack([x, get_img_by_char(chars[i])])\n",
    "    x = cv2.resize(x, (400, 80))\n",
    "#     x = skimage.util.random_noise(x, mode='gaussian', clip=True)\n",
    "#     print('get_sequence_img output')\n",
    "#     plt.imshow(x)\n",
    "#     plt.show()\n",
    "#     print (chars, x.shape)\n",
    "    return x\n",
    "\n",
    "\n",
    "def gen(batch_size=128, gene=4):\n",
    "#     X = np.zeros((batch_size, width, height, 1), dtype=np.uint8)\n",
    "    X = np.zeros((batch_size, width, height, 3), dtype=np.uint8)  #  make channel = 3\n",
    "\n",
    "    y = np.zeros((batch_size, n_len), dtype=np.uint8)\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            random_str = ''.join([random.choice(characters) for j in range(n_len)])\n",
    "#             random_str = '60/3=20'\n",
    "            tmp = np.array(get_sequence_img(random_str))\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            \n",
    "            #  make channel = 3\n",
    "            tmp0 = np.copy(tmp)\n",
    "            tmp = np.concatenate([tmp, tmp0], axis=2)\n",
    "            tmp = np.concatenate([tmp, tmp0], axis=2)\n",
    "            \n",
    "            tmp = tmp.transpose(1, 0, 2)\n",
    "            \n",
    "            X[i] = tmp\n",
    "            y[i] = [characters.find(x) for x in random_str]\n",
    "            \n",
    "        yield [X, y, np.ones(batch_size) * rnn_length, np.ones(batch_size) * n_len], np.ones(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(batch_size=128, steps=10):\n",
    "    batch_acc = 0\n",
    "    generator = gen(batch_size)\n",
    "    for i in range(steps):\n",
    "        [X_test, y_test, _, _], _ = next(generator)\n",
    "        y_pred = base_model.predict(X_test)\n",
    "        shape = y_pred[:, 2:, :].shape\n",
    "        ctc_decode = K.ctc_decode(y_pred[:, 2:, :], input_length=np.ones(shape[0]) * shape[1])[0][0]\n",
    "        print(K.ctc_decode(y_pred, input_length=np.ones(shape[0]) * shape[1]))\n",
    "        out = K.get_value(ctc_decode)[:, :n_len]\n",
    "        if out.shape[1] == n_len:\n",
    "            batch_acc += (y_test == out).all(axis=1).mean()\n",
    "    return batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(Callback):\n",
    "    def __init__(self):\n",
    "        self.acc = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc = evaluate(steps=20)*100\n",
    "        self.accs.append(acc)\n",
    "        print('')\n",
    "        print('acc: %f%%' % acc)\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input((width, height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(weights='./vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.pooling.MaxPooling2D object at 0x7f18acb18dd8>\n",
      "Tensor(\"block5_pool_3/MaxPool:0\", shape=(?, 12, 2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(vgg.layers[-1])\n",
    "# print(' '.join())\n",
    "print(vgg.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 12, 2, 512)\n",
      "12 1024 512\n"
     ]
    }
   ],
   "source": [
    "tensor_shape = vgg.output.shape\n",
    "print(tensor_shape)\n",
    "\n",
    "rnn_length = tensor_shape[1].value\n",
    "rnn_dimen = tensor_shape[2].value * tensor_shape[3].value\n",
    "units = tensor_shape[3].value\n",
    "\n",
    "print(rnn_length, rnn_dimen, units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bottleneck + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape: (?, 12, 1024)\n",
      "now x's shape: (?, 12, 128)\n",
      "gru1_merged's shape: (?, ?, 128)\n",
      "now x's shape: (?, ?, 256)\n",
      "base_model output shape: (?, 12, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "x = Reshape(input_shape=(vgg.output.shape), target_shape=(rnn_length, rnn_dimen))(vgg.output)\n",
    "print('reshape:', x.shape)\n",
    "\n",
    "rnn_length -= 2\n",
    "\n",
    "x = Dense(128, kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "print('now x\\'s shape:', x.shape)\n",
    "\n",
    "rnn_size = 128\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(x)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1b')(x)\n",
    "gru1_merged = add([gru_1, gru_1b])\n",
    "print('gru1_merged\\'s shape:', gru1_merged.shape)\n",
    "\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2b')(gru1_merged)\n",
    "x = concatenate([gru_2, gru_2b])\n",
    "print('now x\\'s shape:', x.shape)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(n_class, kernel_initializer='he_normal', activation='softmax')(x)\n",
    "\n",
    "base_model = Model(input=input_tensor, output=x)\n",
    "print('base_model output shape:', base_model.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='the_labels', shape=[n_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=(1,), dtype='int64')\n",
    "label_length = Input(name='label_length', shape=(1,), dtype='int64')\n",
    "loss_out = Lambda(ctc_lambda_func, name='ctc')([base_model.output, labels, input_length, label_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=(input_tensor, labels, input_length, label_length), outputs=loss_out)  # 输入列表，输出列表\n",
    "# model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam')\n",
    "model.compile(loss={'ctc':  lambda y_true, y_pred: y_pred}, optimizer='adam')  # y_pred其实是loss_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 19/200 [=>............................] - ETA: 4:02:16 - loss: 13.3458"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(gen(128), steps_per_epoch=200, epochs=2,\n",
    "                        callbacks=[evaluator],\n",
    "                        validation_data=gen(128), validation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
